{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc1d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "from google.adk.agents.llm_agent import Agent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.tools import google_search, AgentTool, ToolContext\n",
    "from google.adk.code_executors import BuiltInCodeExecutor\n",
    "\n",
    "print(\"âœ… ADK components imported successfully.\")\n",
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Optional\n",
    "\n",
    "cred = credentials.Certificate(\"lanaagent-firebase-adminsdk-fbsvc-3ed45f99b9.json\")\n",
    "firebase_admin.initialize_app(cred)\n",
    "\n",
    "db=firestore.client()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c03e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helpers and tools\n",
    "\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=3,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")\n",
    "\n",
    "def log_persistence(log_entry_data: dict, is_authenticated: bool) -> bool:\n",
    "    \"\"\"USAGE: Call only when the user explicitly requests persisting a log entry.\n",
    "    Do NOT call during casual conversation.\n",
    "\n",
    "    Saves a structured log entry to the Google Cloud Persistence Store (Firestore).\n",
    "    Includes a Contact Gate check and an auto-generated timestamp.\n",
    "\n",
    "    It also controls the sharing of contact information based on authentication status.\n",
    "\n",
    "    Args:\n",
    "        log_entry_data (dict): The log entry dictionary with this structure:\n",
    "            {\n",
    "                \"timestamp\": \"ISO 8601\",\n",
    "                \"category\": \"Structural/Time, Persona, Avoidance, or Project\",\n",
    "                \"key\": \"The specific field name (e.g., 'Preferred Communication Tone')\",\n",
    "                \"value\": \"The current data value\",\n",
    "                \"source\": \"e.g., 'User Input', 'Bujo OCR', 'Agent Check'\"\n",
    "            }\n",
    "        is_authenticated (bool): Boolean flag indicating if the user is logged into \n",
    "                          their Google Account (True) or anonymous (False).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the log was successfully written; False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # 1. Structural Check: The Contact Gate (for ethical protection)\n",
    "    if log_entry_data.get('key') == 'contact_info' and not is_authenticated:\n",
    "        print(\"ACCESS DENIED: Cannot share contact info for anonymous user.\")\n",
    "        # We do not log the entry to prevent accidental data leakage\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # 2. Add Required Metadata (Timestamp)\n",
    "        # Create a new dictionary to ensure we always log a timestamp\n",
    "        data_to_log = log_entry_data.copy()\n",
    "        data_to_log['timestamp'] = datetime.utcnow()\n",
    "        \n",
    "        # 3. Cloud Write: Writing the data to the 'logs' collection in Firestore\n",
    "        db.collection('logs').add(data_to_log)\n",
    "        \n",
    "        print(f\"SUCCESS: Logged data to Firestore: {log_entry_data.get('key')}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"FAILURE: Could not write to Firestore. Error: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81086b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tools part 2\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Optional\n",
    "def query_persistence(task_id: str) -> dict:\n",
    "    \"\"\"USAGE: Only call this tool when explicitly asked to inspect persistence for a task.\n",
    "    Do NOT call during casual conversation.\n",
    "\n",
    "    Queries the Persistence Store (Firestore) for a specific task's history \n",
    "    and checks if the Contradiction Flag should be raised.\n",
    "    \n",
    "    Args:\n",
    "        task_id: The unique identifier (Task Key) of the task to search for.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the check result and failure count.\n",
    "    \"\"\"\n",
    "    \n",
    "    logs_ref = db.collection('logs').where('key', '==', task_id)\n",
    "    \n",
    "    flag_raised = True if logs_ref is None else False\n",
    "    \n",
    "    # Simulate a successful query that found 4 failures in a row\n",
    "    consecutive_failure_count = 4 \n",
    "\n",
    "    # THE CONTRADICTION FLAG LOGIC \n",
    "    flag_raised = consecutive_failure_count >= 3\n",
    "\n",
    "    return {\n",
    "        \"task_id\": task_id,\n",
    "        \"consecutive_failures\": consecutive_failure_count,\n",
    "        \"flag_raised\": flag_raised\n",
    "    }\n",
    "\n",
    "def _parse_date_token(date_str: str) -> datetime:\n",
    "    \"\"\"\n",
    "    Parse a date string that may be either an ISO date or a relative token.\n",
    "\n",
    "    Supported formats:\n",
    "    - ISO date: 'YYYY-MM-DD' (e.g., '2025-11-24')\n",
    "    - Relative tokens: 'NOW', 'TODAY', 'NOW-7DAYS', 'NOW-30DAYS' (case-insensitive)\n",
    "\n",
    "    Returns a timezone-naive UTC datetime at the start of the day.\n",
    "    Raises ValueError for unsupported formats.\n",
    "    \"\"\"\n",
    "    if not isinstance(date_str, str):\n",
    "        raise ValueError(\"date_str must be a string\")\n",
    "\n",
    "    token = date_str.strip().upper()\n",
    "    if token in (\"NOW\", \"TODAY\"):\n",
    "        return datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "    # Handle patterns like NOW-7DAYS or TODAY-1DAYS\n",
    "    if (token.startswith(\"NOW-\") or token.startswith(\"TODAY-\")) and \"DAYS\" in token:\n",
    "        try:\n",
    "            # last part expected to be like '7DAYS' -> extract leading integer\n",
    "            n_part = token.split(\"-\")[-1]\n",
    "            n = int(''.join(ch for ch in n_part if ch.isdigit()))\n",
    "            return (datetime.utcnow() - timedelta(days=n)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Could not parse relative date token: {date_str}\") from e\n",
    "\n",
    "    # Fallback: try ISO format\n",
    "    try:\n",
    "        return datetime.strptime(token, \"%Y-%m-%d\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Unsupported date format: {date_str}. Use 'YYYY-MM-DD' or 'NOW-<NDAYS>'\") from e\n",
    "\n",
    "\n",
    "def make_a_report(start_date_str: str, end_date_str: str) -> dict:\n",
    "    \"\"\"USAGE: Only call this tool when the user explicitly requests a time-bound report\n",
    "    from persistence (e.g., \"summarize logs from 2025-11-01 to 2025-11-08\").\n",
    "    Do NOT call during casual conversation.\n",
    "\n",
    "    Queries the Persistence Store (Firestore) for a date span and returns matching logs.\n",
    "\n",
    "    Accepted date formats:\n",
    "    - ISO date: 'YYYY-MM-DD' (e.g., '2025-11-01')\n",
    "    - Relative tokens: 'NOW', 'TODAY', 'NOW-7DAYS' (case-insensitive)\n",
    "\n",
    "    Args:\n",
    "        start_date_str: Start date string or relative token.\n",
    "        end_date_str: End date string or relative token.\n",
    "\n",
    "    Returns:\n",
    "        dict: { 'logs': [ ... ] }\n",
    "    \"\"\"\n",
    "    # Parse inputs (accept tokens like NOW-7DAYS)\n",
    "    start_date = _parse_date_token(start_date_str)\n",
    "    end_date = _parse_date_token(end_date_str)\n",
    "\n",
    "    # Ensure end_date includes the full day\n",
    "    end_date = end_date.replace(hour=23, minute=59, second=59, microsecond=999999)\n",
    "\n",
    "    # Execute the query and stream the data\n",
    "    logs_stream = db.collection('logs').where('timestamp', '>', start_date).where('timestamp', '<', end_date).stream()\n",
    "\n",
    "    # Return the data as a list of dictionaries\n",
    "    logs_data = [log.to_dict() for log in logs_stream]\n",
    "\n",
    "    return {\n",
    "        \"logs\": logs_data\n",
    "    }\n",
    "\n",
    "def write_project(project_data: dict) -> dict:\n",
    "        \"\"\"USAGE: Call only when the user explicitly requests creating or updating a project.\n",
    "        Do NOT call for regular chat or unrelated questions.\n",
    "\n",
    "        Write or update a project document to the `projects` collection in Firestore.\n",
    "\n",
    "        Behavior:\n",
    "        - If `project_data` contains a `doc_id` key, the function updates that document (merge=True).\n",
    "        - Otherwise it creates a new document (auto-generated ID).\n",
    "\n",
    "        Expected project_data keys (based on SQL schema):\n",
    "            - project_name (required), project_type (required), description, deadline (YYYY-MM-DD or datetime),\n",
    "            - status, priority, estimated_hours, actual_hours, category_id, completed_date, notes\n",
    "\n",
    "        Returns dict: { 'success': bool, 'doc_id': str (if created/updated), 'data': dict, 'error': str (if any) }\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not isinstance(project_data, dict):\n",
    "                raise ValueError(\"project_data must be a dict\")\n",
    "\n",
    "            # Required fields\n",
    "            if not project_data.get(\"project_name\") or not project_data.get(\"project_type\"):\n",
    "                raise ValueError(\"project_data must include 'project_name' and 'project_type'\")\n",
    "\n",
    "            data = project_data.copy()\n",
    "\n",
    "            # Normalize date fields if provided as strings\n",
    "            for date_field in (\"deadline\", \"created_date\", \"completed_date\"):\n",
    "                if date_field in data and isinstance(data[date_field], str):\n",
    "                    try:\n",
    "                        data[date_field] = datetime.strptime(data[date_field], \"%Y-%m-%d\")\n",
    "                    except Exception:\n",
    "                        # leave as-is if parse fails; Firestore can accept string but we try to be helpful\n",
    "                        pass\n",
    "\n",
    "            # Defaults\n",
    "            data.setdefault(\"status\", \"active\")\n",
    "            data.setdefault(\"actual_hours\", 0)\n",
    "            data.setdefault(\"created_date\", datetime.utcnow())\n",
    "\n",
    "            # If doc_id provided, update existing doc\n",
    "            doc_id = data.pop(\"doc_id\", None)\n",
    "            if doc_id:\n",
    "                doc_ref = db.collection(\"projects\").document(str(doc_id))\n",
    "                doc_ref.set(data, merge=True)\n",
    "                return {\"success\": True, \"doc_id\": doc_id, \"data\": data}\n",
    "            else:\n",
    "                doc_ref = db.collection(\"projects\").add(data)[1]\n",
    "                # Firestore Python client returns (write_result) on add; to get id we need to use the returned DocumentReference\n",
    "                # However `add` returns (doc_ref, write_result) depending on version; handle both\n",
    "                try:\n",
    "                    new_doc_id = doc_ref.id\n",
    "                except Exception:\n",
    "                    # fallback: if first element was the doc_ref\n",
    "                    new_doc_id = None\n",
    "                return {\"success\": True, \"doc_id\": new_doc_id, \"data\": data}\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "\n",
    "def read_projects(filter_by: Optional[dict] = None, limit: int = 100) -> dict:\n",
    "    \"\"\"USAGE: Call only when the user explicitly requests a project list or lookup.\n",
    "    Do NOT call during casual chat.\n",
    "\n",
    "    Read projects from the `projects` collection.\n",
    "\n",
    "    Args:\n",
    "        filter_by (dict): optional mapping of field -> value to filter with equality.\n",
    "            e.g. { 'status': 'active', 'project_type': 'tech' }\n",
    "        limit (int): maximum number of documents to return.\n",
    "\n",
    "    Returns:\n",
    "        dict: { 'success': bool, 'projects': [dict,...], 'error': str (if any) }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        coll = db.collection(\"projects\")\n",
    "        query = coll\n",
    "        if filter_by:\n",
    "            if not isinstance(filter_by, dict):\n",
    "                raise ValueError(\"filter_by must be a dict mapping field->value\")\n",
    "            for k, v in filter_by.items():\n",
    "                query = query.where(k, \"==\", v)\n",
    "\n",
    "        # Apply a limit to avoid runaway reads\n",
    "        docs = query.limit(limit).stream()\n",
    "        projects = []\n",
    "        for d in docs:\n",
    "            doc = d.to_dict()\n",
    "            doc[\"_doc_id\"] = d.id\n",
    "            projects.append(doc)\n",
    "\n",
    "        return {\"success\": True, \"projects\": projects}\n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "\n",
    "def write_category(category_data: dict) -> dict:\n",
    "        \"\"\"USAGE: Call only when the user explicitly requests creating or updating a category.\n",
    "        Do NOT call during casual chat.\n",
    "\n",
    "        Write or update a category document to the `categories` collection in Firestore.\n",
    "\n",
    "        Behavior:\n",
    "        - If `category_data` contains a `doc_id` key, the function updates that document (merge=True).\n",
    "        - Otherwise it creates a new document (auto-generated ID).\n",
    "\n",
    "        Expected category_data keys (based on SQL schema):\n",
    "            - category_name (required), description, color_code, parent_category_id, is_active\n",
    "\n",
    "        Returns dict: { 'success': bool, 'doc_id': str (if created/updated), 'data': dict, 'error': str (if any) }\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not isinstance(category_data, dict):\n",
    "                raise ValueError(\"category_data must be a dict\")\n",
    "\n",
    "            if not category_data.get(\"category_name\"):\n",
    "                raise ValueError(\"category_data must include 'category_name'\")\n",
    "\n",
    "            data = category_data.copy()\n",
    "\n",
    "            # Normalize boolean\n",
    "            if \"is_active\" in data:\n",
    "                try:\n",
    "                    data[\"is_active\"] = bool(int(data[\"is_active\"])) if isinstance(data[\"is_active\"], (str, int)) else bool(data[\"is_active\"])\n",
    "                except Exception:\n",
    "                    data[\"is_active\"] = True\n",
    "            else:\n",
    "                data.setdefault(\"is_active\", True)\n",
    "\n",
    "            # If doc_id provided, update existing doc\n",
    "            doc_id = data.pop(\"doc_id\", None)\n",
    "            if doc_id:\n",
    "                doc_ref = db.collection(\"categories\").document(str(doc_id))\n",
    "                doc_ref.set(data, merge=True)\n",
    "                return {\"success\": True, \"doc_id\": doc_id, \"data\": data}\n",
    "            else:\n",
    "                add_result = db.collection(\"categories\").add(data)\n",
    "                new_doc_id = None\n",
    "                try:\n",
    "                    new_doc_ref = add_result[0]\n",
    "                    new_doc_id = new_doc_ref.id\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        new_doc_id = add_result.id\n",
    "                    except Exception:\n",
    "                        new_doc_id = None\n",
    "                return {\"success\": True, \"doc_id\": new_doc_id, \"data\": data}\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "\n",
    "def read_categories(filter_by: Optional[dict] = None, limit: int = 100) -> dict:\n",
    "    \"\"\"USAGE: Call only when the user explicitly requests category lookups.\n",
    "    Do NOT call during casual chat.\n",
    "\n",
    "    Read categories from the `categories` collection.\n",
    "\n",
    "    Args:\n",
    "        filter_by (dict): optional mapping of field -> value to filter with equality.\n",
    "            e.g. { 'is_active': True }\n",
    "        limit (int): maximum number of documents to return.\n",
    "\n",
    "    Returns:\n",
    "        dict: { 'success': bool, 'categories': [dict,...], 'error': str (if any) }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        coll = db.collection(\"categories\")\n",
    "        query = coll\n",
    "        if filter_by:\n",
    "            if not isinstance(filter_by, dict):\n",
    "                raise ValueError(\"filter_by must be a dict mapping field->value\")\n",
    "            for k, v in filter_by.items():\n",
    "                query = query.where(k, \"==\", v)\n",
    "\n",
    "        docs = query.limit(limit).stream()\n",
    "        categories = []\n",
    "        for d in docs:\n",
    "            doc = d.to_dict()\n",
    "            doc[\"_doc_id\"] = d.id\n",
    "            categories.append(doc)\n",
    "\n",
    "        return {\"success\": True, \"categories\": categories}\n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "\n",
    "def write_task(task_data: dict) -> dict:\n",
    "        \"\"\"USAGE: Call only when the user explicitly requests creating or updating a task/milestone.\n",
    "        Do NOT call during casual chat.\n",
    "\n",
    "        Write or update a task (milestone) document to the `project_tasks` collection in Firestore.\n",
    "\n",
    "        Behavior:\n",
    "        - If `task_data` contains a `doc_id` key, the function updates that document (merge=True).\n",
    "        - Otherwise it creates a new document (auto-generated ID).\n",
    "\n",
    "        Expected task_data keys (based on SQL schema):\n",
    "            - project_id (required), milestone_name (required), description, due_date (YYYY-MM-DD or datetime),\n",
    "            - status, completed_date\n",
    "\n",
    "        Returns dict: { 'success': bool, 'doc_id': str (if created/updated), 'data': dict, 'error': str (if any) }\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not isinstance(task_data, dict):\n",
    "                raise ValueError(\"task_data must be a dict\")\n",
    "\n",
    "            # Required fields\n",
    "            if not task_data.get(\"project_id\") or not task_data.get(\"milestone_name\"):\n",
    "                raise ValueError(\"task_data must include 'project_id' and 'milestone_name'\")\n",
    "\n",
    "            data = task_data.copy()\n",
    "\n",
    "            # Normalize date fields if provided as strings\n",
    "            for date_field in (\"due_date\", \"completed_date\"):\n",
    "                if date_field in data and isinstance(data[date_field], str):\n",
    "                    try:\n",
    "                        data[date_field] = datetime.strptime(data[date_field], \"%Y-%m-%d\")\n",
    "                    except Exception:\n",
    "                        # leave as-is if parse fails; Firestore can accept string but we try to be helpful\n",
    "                        pass\n",
    "\n",
    "            # Defaults\n",
    "            data.setdefault(\"status\", \"pending\")\n",
    "\n",
    "            # If doc_id provided, update existing doc\n",
    "            doc_id = data.pop(\"doc_id\", None)\n",
    "            if doc_id:\n",
    "                doc_ref = db.collection(\"project_tasks\").document(str(doc_id))\n",
    "                doc_ref.set(data, merge=True)\n",
    "                return {\"success\": True, \"doc_id\": doc_id, \"data\": data}\n",
    "            else:\n",
    "                # Add new document\n",
    "                add_result = db.collection(\"project_tasks\").add(data)\n",
    "                # add_result may be (doc_ref, write_result) or doc_ref depending on client\n",
    "                new_doc_id = None\n",
    "                try:\n",
    "                    # If add returns (doc_ref, write_result)\n",
    "                    new_doc_ref = add_result[0]\n",
    "                    new_doc_id = new_doc_ref.id\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        # If add returned a DocumentReference directly\n",
    "                        new_doc_id = add_result.id\n",
    "                    except Exception:\n",
    "                        new_doc_id = None\n",
    "\n",
    "                return {\"success\": True, \"doc_id\": new_doc_id, \"data\": data}\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "\n",
    "def read_tasks(filter_by: Optional[dict] = None, limit: int = 100) -> dict:\n",
    "    \"\"\"USAGE: Call only when the user explicitly requests tasks or milestone lookups.\n",
    "    Do NOT call during casual chat.\n",
    "\n",
    "    Read tasks (milestones) from the `project_tasks` collection.\n",
    "\n",
    "    Args:\n",
    "        filter_by (dict): optional mapping of field -> value to filter with equality.\n",
    "            e.g. { 'project_id': 123, 'status': 'pending' }\n",
    "        limit (int): maximum number of documents to return.\n",
    "\n",
    "    Returns:\n",
    "        dict: { 'success': bool, 'tasks': [dict,...], 'error': str (if any) }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        coll = db.collection(\"project_tasks\")\n",
    "        query = coll\n",
    "        if filter_by:\n",
    "            if not isinstance(filter_by, dict):\n",
    "                raise ValueError(\"filter_by must be a dict mapping field->value\")\n",
    "            for k, v in filter_by.items():\n",
    "                query = query.where(k, \"==\", v)\n",
    "\n",
    "        docs = query.limit(limit).stream()\n",
    "        tasks = []\n",
    "        for d in docs:\n",
    "            doc = d.to_dict()\n",
    "            doc[\"_doc_id\"] = d.id\n",
    "            tasks.append(doc)\n",
    "\n",
    "        return {\"success\": True, \"tasks\": tasks}\n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the log_analyst_agent (keeps read/report tools isolated from root_agent)\n",
    "log_analyst_agent = Agent(\n",
    "    name=\"log_analyst_agent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are a productivity log analyst and objective structural evaluator.\n",
    "    Your sole purpose is to analyze the Persistence Store data using your tools and provide objective assessments.\n",
    "    If asked about commitment status, run the 'query_persistence' tool to check the Contradiction Flag.\n",
    "    If asked for a summary (daily, weekly, monthly), run the 'make_a_report' tool and provide structural insights based on logged avoidance patterns and corrective actions.\n",
    "    Your output must be non-judgmental and focused on systemic improvement.\n",
    "    \"\"\",\n",
    "    tools=[query_persistence, make_a_report],\n",
    ")\n",
    "print(\"âœ… log_analyst_agent created with custom function tools\")\n",
    "print(\"ðŸ”§ Available tools:\", [t.__name__ if hasattr(t, '__name__') else str(t) for t in log_analyst_agent.tools])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046ce70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Root Agent defined.\n"
     ]
    }
   ],
   "source": [
    "root_agent = Agent(\n",
    "    name='root_agent',\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    description='Lanas personal assistant',\n",
    "    instruction=\"\"\"You are a productivity log analyst and objective structural evaluator. \n",
    "    Your sole purpose is to analyze the Persistence Store data using your tools and provide objective assessments.\n",
    "    \n",
    "    If asked about commitment status, run the 'query_persistence' tool to check the Contradiction Flag.\n",
    "    If asked for a summary (daily, weekly, monthly), run the 'make_a_report' tool and provide structural insights based on logged avoidance patterns and corrective actions.\n",
    "    Your output must be non-judgmental and focused on systemic improvement.\n",
    "    If user is trivially chatting, do not use any tools and respond casually.\n",
    "    \"\"\",\n",
    "    tools=[\n",
    "        log_persistence,\n",
    "        AgentTool(agent=log_analyst_agent),\n",
    "        # Expose write-only helpers on root_agent. Read/report tools live on log_analyst_agent and should only be invoked via AgentTool.\n",
    "        write_project,\n",
    "        write_task,\n",
    "        write_category,\n",
    "    ]\n",
    ")\n",
    "print(\"âœ… Root Agent defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff2fc1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Runner created.\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(agent=root_agent)\n",
    "\n",
    "print(\"âœ… Runner created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34ff6832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Continue session: debug_session_id\n",
      "\n",
      "User > Hi buddy\n",
      "root_agent > Hello! How can I help you today?\n",
      "root_agent > Hello! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "response = await runner.run_debug(\"Hi buddy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dc4f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test the log_analyst_agent\n",
    "log_analyst_runner = InMemoryRunner(agent=log_analyst_agent)\n",
    "_ = await log_analyst_runner.run_debug(\n",
    "    \"what was completed today from 2025-11-23 to 2025-11-24\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390c4c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Continue session: debug_session_id\n",
      "\n",
      "User > can you provide a summary of my productivity logs for the past week?\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Default value None of parameter filter_by: dict = None of function read_projects is not compatible with the parameter annotation <class 'dict'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m runner.run_debug(\u001b[33m\"\u001b[39m\u001b[33mcan you provide a summary of my productivity logs for the past week?\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\anaconda3\\envs\\about_Lana_agent\\Lib\\site-packages\\google\\adk\\runners.py:1023\u001b[39m, in \u001b[36mRunner.run_debug\u001b[39m\u001b[34m(self, user_messages, user_id, session_id, run_config, quiet, verbose)\u001b[39m\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   1021\u001b[39m   \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mUser > \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_async(\n\u001b[32m   1024\u001b[39m     user_id=user_id,\n\u001b[32m   1025\u001b[39m     session_id=session.id,\n\u001b[32m   1026\u001b[39m     new_message=types.UserContent(parts=[types.Part(text=message)]),\n\u001b[32m   1027\u001b[39m     run_config=run_config,\n\u001b[32m   1028\u001b[39m ):\n\u001b[32m   1029\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   1030\u001b[39m     print_event(event, verbose=verbose)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\anaconda3\\envs\\about_Lana_agent\\Lib\\site-packages\\google\\adk\\runners.py:443\u001b[39m, in \u001b[36mRunner.run_async\u001b[39m\u001b[34m(self, user_id, session_id, invocation_id, new_message, state_delta, run_config)\u001b[39m\n\u001b[32m    436\u001b[39m       asyncio.create_task(\n\u001b[32m    437\u001b[39m           _run_compaction_for_sliding_window(\n\u001b[32m    438\u001b[39m               \u001b[38;5;28mself\u001b[39m.app, session, \u001b[38;5;28mself\u001b[39m.session_service\n\u001b[32m    439\u001b[39m           )\n\u001b[32m    440\u001b[39m       )\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_run_with_trace(new_message, invocation_id)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\anaconda3\\envs\\about_Lana_agent\\Lib\\site-packages\\google\\adk\\runners.py:427\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace\u001b[39m\u001b[34m(new_message, invocation_id)\u001b[39m\n\u001b[32m    417\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    420\u001b[39m     \u001b[38;5;28mself\u001b[39m._exec_with_plugin(\n\u001b[32m    421\u001b[39m         invocation_context=invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    425\u001b[39m     )\n\u001b[32m    426\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# Run compaction after all events are yielded from the agent.\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;66;03m# (We don't compact in the middle of an invocation, we only compact at the end of an invocation.)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\anaconda3\\envs\\about_Lana_agent\\Lib\\site-packages\\google\\adk\\runners.py:653\u001b[39m, in \u001b[36mRunner._exec_with_plugin\u001b[39m\u001b[34m(self, invocation_context, session, execute_fn, is_live_call)\u001b[39m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    651\u001b[39m   \u001b[38;5;66;03m# Step 2: Otherwise continue with normal execution\u001b[39;00m\n\u001b[32m    652\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(execute_fn(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    654\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m event.partial:\n\u001b[32m    655\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_append_event(event, is_live_call):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\anaconda3\\envs\\about_Lana_agent\\Lib\\site-packages\\google\\adk\\runners.py:416\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace.<locals>.execute\u001b[39m\u001b[34m(ctx)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(ctx: InvocationContext) -> AsyncGenerator[Event]:\n\u001b[32m    415\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(ctx.agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    417\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\anaconda3\\envs\\about_Lana_agent\\Lib\\site-packages\\google\\adk\\agents\\base_agent.py:294\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    291\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\anaconda3\\envs\\about_Lana_agent\\Lib\\site-packages\\google\\adk\\agents\\llm_agent.py:435\u001b[39m, in \u001b[36mLlmAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    433\u001b[39m should_pause = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._llm_flow.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    436\u001b[39m     \u001b[38;5;28mself\u001b[39m.__maybe_save_output_to_state(event)\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\anaconda3\\envs\\about_Lana_agent\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:356\u001b[39m, in \u001b[36mBaseLlmFlow.run_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    354\u001b[39m last_event = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_one_step_async(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    357\u001b[39m     last_event = event\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\anaconda3\\envs\\about_Lana_agent\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:375\u001b[39m, in \u001b[36mBaseLlmFlow._run_one_step_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# Preprocess before calling the LLM.\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    373\u001b[39m     \u001b[38;5;28mself\u001b[39m._preprocess_async(invocation_context, llm_request)\n\u001b[32m    374\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m invocation_context.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\anaconda3\\envs\\about_Lana_agent\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:493\u001b[39m, in \u001b[36mBaseLlmFlow._preprocess_async\u001b[39m\u001b[34m(self, invocation_context, llm_request)\u001b[39m\n\u001b[32m    486\u001b[39m tools = \u001b[38;5;28;01mawait\u001b[39;00m _convert_tool_union_to_tools(\n\u001b[32m    487\u001b[39m     tool_union,\n\u001b[32m    488\u001b[39m     ReadonlyContext(invocation_context),\n\u001b[32m    489\u001b[39m     agent.model,\n\u001b[32m    490\u001b[39m     multiple_tools,\n\u001b[32m    491\u001b[39m )\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m   \u001b[38;5;28;01mawait\u001b[39;00m tool.process_llm_request(\n\u001b[32m    494\u001b[39m       tool_context=tool_context, llm_request=llm_request\n\u001b[32m    495\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\anaconda3\\envs\\about_Lana_agent\\Lib\\site-packages\\google\\adk\\tools\\base_tool.py:129\u001b[39m, in \u001b[36mBaseTool.process_llm_request\u001b[39m\u001b[34m(self, tool_context, llm_request)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Processes the outgoing LLM request for this tool.\u001b[39;00m\n\u001b[32m    119\u001b[39m \n\u001b[32m    120\u001b[39m \u001b[33;03mUse cases:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    126\u001b[39m \u001b[33;03m  llm_request: The outgoing LLM request, mutable this method.\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# Use the consolidated logic in LlmRequest.append_tools\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m \u001b[43mllm_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\anaconda3\\envs\\about_Lana_agent\\Lib\\site-packages\\google\\adk\\models\\llm_request.py:247\u001b[39m, in \u001b[36mLlmRequest.append_tools\u001b[39m\u001b[34m(self, tools)\u001b[39m\n\u001b[32m    245\u001b[39m declarations = []\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools:\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m   declaration = \u001b[43mtool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_declaration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m declaration:\n\u001b[32m    249\u001b[39m     declarations.append(declaration)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\anaconda3\\envs\\about_Lana_agent\\Lib\\site-packages\\google\\adk\\tools\\function_tool.py:89\u001b[39m, in \u001b[36mFunctionTool._get_declaration\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_declaration\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Optional[types.FunctionDeclaration]:\n\u001b[32m     88\u001b[39m   function_decl = types.FunctionDeclaration.model_validate(\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m       \u001b[43mbuild_function_declaration\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m          \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# The model doesn't understand the function context.\u001b[39;49;00m\n\u001b[32m     92\u001b[39m \u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# input_stream is for streaming tool\u001b[39;49;00m\n\u001b[32m     93\u001b[39m \u001b[43m          \u001b[49m\u001b[43mignore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ignore_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m          \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_variant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m   )\n\u001b[32m     98\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m function_decl\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\anaconda3\\envs\\about_Lana_agent\\Lib\\site-packages\\google\\adk\\tools\\_automatic_function_calling_util.py:235\u001b[39m, in \u001b[36mbuild_function_declaration\u001b[39m\u001b[34m(func, ignore_params, variant)\u001b[39m\n\u001b[32m    231\u001b[39m     new_func.\u001b[34m__doc__\u001b[39m = func.\u001b[34m__doc__\u001b[39m\n\u001b[32m    232\u001b[39m     new_func.\u001b[34m__annotations__\u001b[39m = func.\u001b[34m__annotations__\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     \u001b[43mfrom_function_with_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_update_signature\n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m from_function_with_options(new_func, variant)\n\u001b[32m    238\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\anaconda3\\envs\\about_Lana_agent\\Lib\\site-packages\\google\\adk\\tools\\_automatic_function_calling_util.py:309\u001b[39m, in \u001b[36mfrom_function_with_options\u001b[39m\u001b[34m(func, variant)\u001b[39m\n\u001b[32m    306\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param.annotation, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    307\u001b[39m       param = param.replace(annotation=typing.get_type_hints(func)[name])\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     schema = \u001b[43m_function_parameter_parse_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_parse_schema_from_parameter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m     parameters_properties[name] = schema\n\u001b[32m    313\u001b[39m declaration = types.FunctionDeclaration(\n\u001b[32m    314\u001b[39m     name=func.\u001b[34m__name__\u001b[39m,\n\u001b[32m    315\u001b[39m     description=func.\u001b[34m__doc__\u001b[39m,\n\u001b[32m    316\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\anaconda3\\envs\\about_Lana_agent\\Lib\\site-packages\\google\\adk\\tools\\_function_parameter_parse_util.py:144\u001b[39m, in \u001b[36m_parse_schema_from_parameter\u001b[39m\u001b[34m(variant, param, func_name)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m param.default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect.Parameter.empty:\n\u001b[32m    143\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_default_value_compatible(param.default, param.annotation):\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(default_value_error_msg)\n\u001b[32m    145\u001b[39m   schema.default = param.default\n\u001b[32m    146\u001b[39m schema.type = _py_builtin_type_to_schema_type[param.annotation]\n",
      "\u001b[31mValueError\u001b[39m: Default value None of parameter filter_by: dict = None of function read_projects is not compatible with the parameter annotation <class 'dict'>."
     ]
    }
   ],
   "source": [
    "# Duplicate interactive test disabled to avoid accidental double calls\n",
    "# response = await runner.run_debug(\"can you provide a summary of my productivity logs for the past week?\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate interactive test disabled to avoid accidental double calls\n",
    "# response = await runner.run_debug(\"can you provide a summary of my productivity logs for the past week?\")\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "about_Lana_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
